{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "from yaml import Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset\n",
    "\n",
    "train_path = 'split_set/train'\n",
    "test_path = 'split_set/test'\n",
    "val_path = 'split_set/val'\n",
    "\n",
    "architecture_vocab = ['Conv2d', 'Linear', 'MaxPool2d', 'BatchNorm2d', 'Dropout2d', 'ReLU', 'SELU', 'LeakyReLU', 'Flatten', 'Tanh', 'BatchNorm1d', 'Dropout', 'Softmax']\n",
    "optimizer_vocab = ['SGD', 'Adam', 'Adadelta', 'Adagrad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training set\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for filename in Path(train_path).glob('**/meta_data.yml'):\n",
    "    data_item = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        yamldata = yaml.load(f, Loader=Loader)\n",
    "        data_item['mdl_str'] = yamldata['arch_and_hp']\n",
    "        data_item['train_loss'] = yamldata['train_loss']\n",
    "        data_item['train_error'] = yamldata['train_error']\n",
    "        data_item['val_loss'] = yamldata['val_loss']\n",
    "        data_item['val_error'] = yamldata['val_error']\n",
    "        data_item['test_loss'] = yamldata['test_loss']\n",
    "        data_item['test_error'] = yamldata['test_error']\n",
    "        data_item['mdl_vect'] = [vocab in data_item['mdl_str'] for vocab in architecture_vocab]\n",
    "    \n",
    "    train_data.append(data_item)\n",
    "    \n",
    "train_data = np.array(train_data)\n",
    "\n",
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for data_item in train_data:\n",
    "    train_X.append(data_item['mdl_vect'])\n",
    "    train_y.append(data_item['test_error'])\n",
    "    \n",
    "train_X = np.array(train_X, dtype=int)\n",
    "train_y = np.array(train_y, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for filename in Path(test_path).glob('**/meta_data.yml'):\n",
    "    data_item = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        yamldata = yaml.load(f, Loader=Loader)\n",
    "        data_item['mdl_str'] = yamldata['arch_and_hp']\n",
    "        data_item['train_loss'] = yamldata['train_loss']\n",
    "        data_item['train_error'] = yamldata['train_error']\n",
    "        data_item['val_loss'] = yamldata['val_loss']\n",
    "        data_item['val_error'] = yamldata['val_error']\n",
    "        data_item['test_loss'] = yamldata['test_loss']\n",
    "        data_item['test_error'] = yamldata['test_error']\n",
    "        data_item['mdl_vect'] = [vocab in data_item['mdl_str'] for vocab in architecture_vocab]\n",
    "    \n",
    "    test_data.append(data_item)\n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "\n",
    "test_X = []\n",
    "test_y = []\n",
    "\n",
    "for data_item in test_data:\n",
    "    test_X.append(data_item['mdl_vect'])\n",
    "    test_y.append(data_item['test_error'])\n",
    "    \n",
    "test_X = np.array(test_X, dtype=int)\n",
    "test_y = np.array(test_y, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation set\n",
    "\n",
    "val_data = []\n",
    "\n",
    "for filename in Path(val_path).glob('**/meta_data.yml'):\n",
    "    data_item = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        yamldata = yaml.load(f, Loader=Loader)\n",
    "        data_item['mdl_str'] = yamldata['arch_and_hp']\n",
    "        data_item['train_loss'] = yamldata['train_loss']\n",
    "        data_item['train_error'] = yamldata['train_error']\n",
    "        data_item['val_loss'] = yamldata['val_loss']\n",
    "        data_item['val_error'] = yamldata['val_error']\n",
    "        data_item['test_loss'] = yamldata['test_loss']\n",
    "        data_item['test_error'] = yamldata['test_error']\n",
    "        data_item['mdl_vect'] = [vocab in data_item['mdl_str'] for vocab in architecture_vocab]\n",
    "    \n",
    "    val_data.append(data_item)\n",
    "    \n",
    "val_data = np.array(val_data)\n",
    "\n",
    "val_X = []\n",
    "val_y = []\n",
    "\n",
    "for data_item in val_data:\n",
    "    val_X.append(data_item['mdl_vect'])\n",
    "    val_y.append(data_item['test_error'])\n",
    "    \n",
    "val_X = np.array(val_X, dtype=int)\n",
    "val_y = np.array(val_y, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(train_X, train_y)\n",
    "ridge = Ridge(alpha=1.0).fit(train_X, train_y)\n",
    "knn = KNeighborsRegressor(n_neighbors=15).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression, Ridge Regression, KNN\n",
      "2.280754121139546 2.2809928846553778 2.183812427775065\n"
     ]
    }
   ],
   "source": [
    "test_y_reg = reg.predict(test_X)\n",
    "reg_err = np.sum((test_y_reg - test_y) ** 2)\n",
    "\n",
    "test_y_ridge = ridge.predict(test_X)\n",
    "ridge_err = np.sum((test_y_ridge - test_y) ** 2)\n",
    "\n",
    "test_y_knn = knn.predict(test_X)\n",
    "knn_err = np.sum((test_y_knn - test_y) ** 2)\n",
    "\n",
    "print(\"Sum of Squared Errors for:\")\n",
    "print(\"Linear Regression, Ridge Regression, KNN\")\n",
    "print(reg_err, ridge_err, knn_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
