import matplotlib.pyplot as plt

min_train_errors_azure = [0.6217919588088989, 0.1865830272436142, 0.721875, 0.727734375, 0.6622472405433655, 0.5163130760192871, 0.72265625, 0.6281407475471497, 0.716015625, 0.6772503852844238, 0.723828125, 0.6033194065093994, 0.7171875, 0.7234375, 0.6645075678825378, 0.08016807585954666, 0.15709534287452698, 0.716015625, 0.3254297375679016, 0.5844652652740479, 0.4736916124820709, 0.5298315286636353, 0.5098010301589966, 0.6696633696556091, 0.09977953135967255, 0.3621777594089508, 0.719921875, 0.72109375, 0.3638637959957123, 0.0, 0.70703125, 0.71953125, 0.724609375, 0.72109375, 0.649164080619812, 0.725, 0.7047495245933533, 0.5695672631263733, 0.7125, 0.726171875, 0.6653871536254883, 0.4506399929523468, 0.12182072550058365, 0.723046875, 0.7171875, 0.4239990711212158, 0.724609375, 0.7127555012702942, 0.726171875, 0.723046875, 0.4864204227924347, 0.4531877040863037, 0.71796875, 0.7218526005744934, 0.36871036887168884, 0.5622020959854126, 0.715234375, 0.22125916182994843, 0.4962351322174072, 0.5796774625778198, 0.6036772727966309, 0.12368740886449814, 0.5910013914108276, 0.721484375, 0.72734375, 0.720703125, 0.6283759474754333, 0.717578125, 0.72421875, 0.2532373070716858, 0.721875, 0.7046875, 0.730078125, 0.19894541800022125, 0.31552547216415405, 0.7089431285858154, 0.71875, 0.719921875, 0.4349932074546814, 0.7125, 0.45347896218299866, 0.4860730767250061, 0.5931270122528076, 0.688089907169342, 0.714453125, 0.0, 0.6680182218551636, 0.5094000101089478, 0.6094673275947571, 0.621251106262207, 0.730859375, 0.3470379412174225, 0.1894928365945816, 0.725, 0.09315697848796844, 0.7173802256584167, 0.706860363483429, 0.28746020793914795, 0.29285740852355957, 0.2460303008556366, 0.72421875, 0.5508497953414917]

min_test_errors_azure= [0.49375, 0.4544921875, 0.5388671875, 0.50234375, 0.5001953125, 0.4546875, 0.687109375, 0.5423828125, 0.519921875, 0.499609375, 0.651171875, 0.418359375, 0.52734375, 0.533984375, 0.5337890625, 0.4658203125, 0.4234375, 0.4662109375, 0.2841796875, 0.5078125, 0.4275390625, 0.560546875, 0.4849609375, 0.5173828125, 0.430078125, 0.46015625, 0.6474609375, 0.5396484375, 0.4912109375, 0.4177734375, 0.4818359375, 0.6333984375, 0.658203125, 0.6283203125, 0.4728515625, 0.4640625, 0.5216796875, 0.4626953125, 0.530078125, 0.6462890625, 0.5408203125, 0.4345703125, 0.4396484375, 0.4990234375, 0.5373046875, 0.3814453125, 0.6037109375, 0.471875, 0.6373046875, 0.44453125, 0.4841796875, 0.4689453125, 0.5740234375, 0.5052734375, 0.4583984375, 0.5896484375, 0.50859375, 0.4345703125, 0.4478515625, 0.466796875, 0.4716796875, 0.4779296875, 0.480859375, 0.412109375, 0.519140625, 0.4126953125, 0.453515625, 0.43203125, 0.71171875, 0.416015625, 0.6388671875, 0.53828125, 0.6681640625, 0.4126953125, 0.4544921875, 0.4931640625, 0.7115234375, 0.5158203125, 0.4375, 0.5751953125, 0.4521484375, 0.4900390625, 0.54375, 0.4974609375, 0.5939453125, 0.372265625, 0.547265625, 0.5509765625, 0.4330078125, 0.498828125, 0.676171875, 0.488671875, 0.4390625, 0.711328125, 0.4759765625, 0.525390625, 0.554296875, 0.4423828125, 0.449609375, 0.5142578125, 0.5458984375, 0.4681640625]



min_train_errors_amazon = [0.621462881565094, 0.71796875, 0.5512605905532837, 0.6350728273391724, 0.24032042920589447, 0.7091159820556641, 0.29024311900138855, 0.02106774039566517, 0.3362046182155609, 0.713671875, 0.723046875, 0.720703125, 0.6911913752555847, 0.715234375, 0.30887722969055176, 0.5425797700881958, 0.733203125, 0.19401197135448456, 0.4577278792858124, 0.5521417856216431, 0.4693889617919922, 0.639886736869812, 0.717578125, 0.27378055453300476, 0.5490828156471252, 0.7203125, 0.6195841431617737, 0.72578125, 0.5859962701797485, 0.6185826659202576, 0.47461992502212524, 0.718359375, 0.5325972437858582, 0.5946942567825317, 0.6794951558113098, 0.7171875, 0.7197495698928833, 0.0, 0.342374712228775, 0.3588641583919525, 0.71484375, 0.71484375, 0.2838382124900818, 0.48906898498535156, 0.708203125, 0.6122435927391052, 0.722265625, 0.4284181296825409, 0.724609375, 0.6110314130783081]
min_test_errors_amazon = [0.4248046875, 0.7103515625, 0.48984375, 0.479296875, 0.4283203125, 0.4818359375, 0.4044921875, 0.39921875, 0.5009765625, 0.5390625, 0.548828125, 0.51640625, 0.40859375, 0.6578125, 0.4142578125, 0.5216796875, 0.6775390625, 0.4412109375, 0.453515625, 0.4427734375, 0.4591796875, 0.506640625, 0.5421875, 0.4259765625, 0.4849609375, 0.7119140625, 0.44609375, 0.710546875, 0.508203125, 0.5240234375, 0.4919921875, 0.625, 0.46015625, 0.438671875, 0.530078125, 0.634375, 0.2953125, 0.4228515625, 0.4642578125, 0.4974609375, 0.56640625, 0.6193359375, 0.3791015625, 0.3806640625, 0.5580078125, 0.5201171875, 0.6677734375, 0.4779296875, 0.5208984375, 0.5453125]

min_train_errors = min_train_errors_amazon + min_train_errors_azure
min_test_errors = min_test_errors_amazon + min_test_errors_azure


# train_errors = train_errors_amazon + train_errors_azure
# test_errors = test_errors_amazon + test_errors_azure
min_differ_test_train = []
for i in range(len(min_test_errors)):
    min_differ_test_train.append(min_test_errors[i]-min_train_errors[i])
# print(len(test_errors))
# print(len(train_errors))
# print(differ_test_train)
#
#
#
print(len(min_test_errors))
# create histograms
plt.hist(min_test_errors, bins = 50)
plt.ylabel('Frequency')
plt.xlabel('errors')
title = 'min_test_errors'
plt.title(title)
# plt.show()
plt.savefig(f'/Users/pangda/predicting_generalization/main_full_auto_ml/data/ploting/mdls_random_{title}.png')
# plt.clf() #clears canvas for new plot

# epochs_list = [i+1 for i in range(479)] #epoch list
# # print(epochs_list)
# plt.plot(epochs_list, train_errors, 'b')
# plt.plot(epochs_list, test_errors, 'r')
# plt.xlabel('Epochs')
# plt.ylabel('Errors')
# title = 'random_grp2_6'
# plt.title(title)
# plt.show()
# plt.savefig(f'/Users/pangda/predicting_generalization/main_full_auto_ml/data/ploting/{title}.png')
# plt.clf() #clears canvas for new plot
